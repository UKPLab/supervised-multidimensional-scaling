{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SMDS by Shape Wizards","text":"<p>A plug-and-play, scikit-learn compatible implementation of Supervised Multi-Dimensional Scaling (SMDS) for automatic feature manifold discovery in LLMs.</p> <p>Install with uv:</p> <pre><code>uv add supervised-multidimensional-scaling\n</code></pre> <p>Install with uv using the <code>pip</code> interface:</p> <pre><code>uv pip install supervised-multidimensional-scaling\n</code></pre> <p>Install with pip:</p> <pre><code>pip install supervised-multidimensional-scaling\n</code></pre>"},{"location":"#docs","title":"Docs","text":"<p>options: members: true show_submodules: true</p>"},{"location":"#smds.SupervisedMDS","title":"<code>SupervisedMDS</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> Source code in <code>smds/smds.py</code> <pre><code>class SupervisedMDS(BaseEstimator, TransformerMixin):  # type: ignore[misc]\n    def __init__(\n        self,\n        manifold: Callable[[np.ndarray], np.ndarray],\n        n_components: int = 2,\n        alpha: float = 0.1,\n        orthonormal: bool = False,\n        radius: float = 6371,\n    ):\n        \"\"\"\n        Parameters:\n            n_components:\n                Dimensionality of the target subspace.\n            manifold:\n                If callable, should return a (n x n) ideal distance matrix given y.\n        \"\"\"\n        self.n_components = n_components\n        self.manifold = manifold\n        self.W_ = None\n        self.alpha = alpha\n        self.orthonormal = orthonormal\n        self.radius = radius  # Only used for spherical manifolds\n        self._X_mean = None\n        self._Y_mean = None\n        if orthonormal and alpha != 0:\n            print(\"Warning: orthonormal=True and alpha!=0. alpha will be ignored.\")\n\n    def _compute_ideal_distances(self, y: np.ndarray, threshold: int = 2) -&gt; np.ndarray:\n        \"\"\"\n        Compute ideal pairwise distance matrix D based on labels y and specified self.manifold.\n        \"\"\"\n        if callable(self.manifold):\n            D: np.ndarray = self.manifold(y)\n        else:\n            raise ValueError(\"Invalid manifold specification.\")\n\n        return D\n\n    def _classical_mds(self, D: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Perform Classical MDS on the distance matrix D to obtain a low-dimensional embedding.\n        This is the template manifold for the supervised MDS.\n        \"\"\"\n        # Square distances\n        D2 = D**2\n\n        # Double centering\n        n = D2.shape[0]\n        H = np.eye(n) - np.ones((n, n)) / n\n        B = -0.5 * H @ D2 @ H\n\n        # Eigen-decomposition\n        eigvals, eigvecs = eigh(B)\n        idx = np.argsort(eigvals)[::-1]\n        eigvals = eigvals[idx][: self.n_components]\n        eigvecs = eigvecs[:, idx][:, : self.n_components]\n\n        # Embedding computation\n        Y: np.ndarray = eigvecs * np.sqrt(np.maximum(eigvals, 0))\n        return Y\n\n    def _masked_loss(self, W_flat: np.ndarray, X: np.ndarray, D: np.ndarray, mask: np.ndarray) -&gt; float:\n        \"\"\"\n        Compute the loss only on the defined distances (where mask is True).\n        \"\"\"\n        W = W_flat.reshape((self.n_components, X.shape[1]))\n        X_proj = (W @ X.T).T\n        D_pred = np.linalg.norm(X_proj[:, None, :] - X_proj[None, :, :], axis=-1)\n        loss = (D_pred - D)[mask]\n        result: float = float(np.sum(loss**2))\n        return result\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -&gt; \"SupervisedMDS\":\n        \"\"\"\n        Fit the linear transformation W to match distances induced by labels y.\n        Uses classical MDS + closed-form when all distances are defined,\n        and switches to optimization if some distances are undefined (negative).\n\n        Parameters:\n            X: array-like of shape (n_samples, n_features)\n                The input data to be transformed.\n            y: array-like of shape (n_samples,) or (n_samples, 2)\n                The labels or coordinates defining the ideal distances.\n        Returns:\n            self: returns an instance of self.\n        \"\"\"\n        X = np.asarray(X)\n        y = np.asarray(y).squeeze()  # Ensure y is 1D\n        D = self._compute_ideal_distances(y)\n\n        if np.any(D &lt; 0):\n            # Raise warning if any distances are negative\n            print(\"Warning: Distance matrix is incomplete. Using optimization to fit W.\")\n            mask = D &gt;= 0\n            rng = np.random.default_rng(42)\n            W0 = rng.normal(scale=0.01, size=(self.n_components, X.shape[1]))\n\n            result = minimize(self._masked_loss, W0.ravel(), args=(X, D, mask), method=\"L-BFGS-B\")\n            self.W_ = result.x.reshape((self.n_components, X.shape[1]))\n        else:\n            # Use classical MDS + closed-form least squares\n            Y = self._classical_mds(D)\n            self.Y_ = Y\n\n            self._X_mean = X.mean(axis=0)  # Centering\n            self._Y_mean = Y.mean(axis=0)  # Centering Y\n            X_centered = X - X.mean(axis=0)\n            Y_centered = Y - Y.mean(axis=0)\n            if self.orthonormal:\n                # Orthogonal Procrustes\n                M = Y_centered.T @ X_centered\n                U, _, Vt = np.linalg.svd(M)\n                self.W_ = U @ Vt\n            else:\n                if self.alpha == 0:\n                    self.W_ = Y_centered.T @ np.linalg.pinv(X_centered.T)\n                else:\n                    XtX = X_centered.T @ X_centered\n                    XtX_reg = XtX + self.alpha * np.eye(XtX.shape[0])\n                    XtX_inv = np.linalg.inv(XtX_reg)\n                    self.W_ = Y_centered.T @ X_centered @ XtX_inv\n\n        return self\n\n    def transform(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Apply the learned transformation to X.\n\n        Parameters:\n            X: array-like of shape (n_samples, n_features)\n                The input data to be transformed.\n        Returns:\n            X_proj: array of shape (n_samples, n_components)\n                The transformed data in the low-dimensional space.\n        \"\"\"\n        if self.W_ is None:\n            raise RuntimeError(\"You must fit the model before calling transform.\")\n        X = np.asarray(X)\n        if self._X_mean is not None:\n            # Center X using the same logic as during fit\n            X_centered = X - self._X_mean\n        else:\n            X_centered = X\n        X_proj: np.ndarray = (self.W_ @ X_centered.T).T\n        return X_proj\n\n    def _truncated_pinv(self, W: np.ndarray, tol: float = 1e-5) -&gt; np.ndarray:\n        U, S, VT = np.linalg.svd(W, full_matrices=False)\n        S_inv = np.array([1 / s if s &gt; tol else 0 for s in S])\n        result: np.ndarray = VT.T @ np.diag(S_inv) @ U.T\n        return result\n\n    def _regularized_pinv(self, W: np.ndarray, lambda_: float = 1e-5) -&gt; np.ndarray:\n        result: np.ndarray = np.linalg.inv(W.T @ W + lambda_ * np.eye(W.shape[1])) @ W.T\n        return result\n\n    def inverse_transform(self, X_proj: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Reconstruct the original input X from its low-dimensional projection.\n\n        Parameters:\n            X_proj: array-like of shape (n_samples, n_components)\n                The low-dimensional representation of the input data.\n\n        Returns:\n            X_reconstructed: array of shape (n_samples, original_n_features)\n                The reconstructed data in the original space.\n        \"\"\"\n        if self.W_ is None:\n            raise RuntimeError(\"You must fit the model before calling inverse_transform.\")\n\n        X_proj = np.asarray(X_proj)\n\n        # Use pseudo-inverse in case W_ is not square or full-rank\n        # W_pinv = np.linalg.pinv(self.W_)\n        # Use regularized pseudo-inverse to avoid numerical issues\n        # W_pinv = self._regularized_pinv(self.W_)\n        W_pinv = self._truncated_pinv(self.W_)\n\n        X_centered: np.ndarray = (W_pinv @ X_proj.T).T\n\n        if hasattr(self, \"_X_mean\") and self._X_mean is not None:\n            result: np.ndarray = X_centered + self._X_mean\n            return result\n        else:\n            return X_centered\n\n    def fit_transform(self, X: np.ndarray, y: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Fit the model and transform X in one step.\n        Parameters:\n            X: array-like of shape (n_samples, n_features)\n                The input data to be transformed.\n            y: array-like of shape (n_samples,) or (n_samples, 2)\n        Returns:\n            X_proj: array of shape (n_samples, n_components)\n                The transformed data in the low-dimensional space.\n        \"\"\"\n        result: np.ndarray = self.fit(X, y).transform(X)\n        return result\n\n    def score(\n        self,\n        X: np.ndarray,\n        y: np.ndarray,\n        metric: StressMetrics = StressMetrics.SCALE_NORMALIZED_STRESS,\n    ) -&gt; float:\n        \"\"\"Evaluate embedding quality using SUPERVISED metric (uses y labels).\"\"\"\n        if self.W_ is None:\n            raise RuntimeError(\"Model must be fit before scoring.\")\n\n        D_ideal = self._compute_ideal_distances(y)\n\n        # Compute predicted pairwise distances\n        X_proj = self.transform(X)\n        n = X_proj.shape[0]\n        D_pred = np.linalg.norm(X_proj[:, np.newaxis, :] - X_proj[np.newaxis, :, :], axis=-1)\n\n        if metric == StressMetrics.NORMALIZED_KL_DIVERGENCE:\n            score_value = kl_divergence_stress(D_ideal, D_pred)\n            score_value = -score_value\n            return score_value\n\n        mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n        mask = mask &amp; (D_ideal &gt;= 0)\n        D_ideal_flat = D_ideal[mask]\n        D_pred_flat = D_pred[mask]\n\n        if metric == StressMetrics.SCALE_NORMALIZED_STRESS:\n            score_value = 1 - scale_normalized_stress(D_ideal_flat, D_pred_flat)\n        elif metric == StressMetrics.NON_METRIC_STRESS:\n            score_value = 1 - non_metric_stress(D_ideal_flat, D_pred_flat)\n        elif metric == StressMetrics.SHEPARD_GOODNESS_SCORE:\n            score_value = shepard_goodness_stress(D_ideal_flat, D_pred_flat)\n        elif metric == StressMetrics.NORMALIZED_STRESS:\n            score_value = 1 - normalized_stress(D_ideal_flat, D_pred_flat)\n        else:\n            raise ValueError(f\"Unknown metric: {metric}\")\n\n        return score_value\n\n    def save(self, filepath: str) -&gt; None:\n        \"\"\"\n        Save the model to disk, including learned weights.\n        \"\"\"\n        if not os.path.exists(os.path.dirname(filepath)):\n            os.makedirs(os.path.dirname(filepath))\n        with open(filepath, \"wb\") as f:\n            pickle.dump(self, f)\n\n    @classmethod\n    def load(cls, filepath: str) -&gt; \"SupervisedMDS\":\n        \"\"\"\n        Load a model from disk.\n        Returns:\n            An instance of SupervisedMDS.\n        \"\"\"\n        with open(filepath, \"rb\") as f:\n            obj = pickle.load(f)\n        if not isinstance(obj, cls):\n            raise TypeError(f\"Loaded object is not a {cls.__name__}\")\n        return obj\n</code></pre>"},{"location":"#smds.SupervisedMDS.__init__","title":"<code>__init__(manifold, n_components=2, alpha=0.1, orthonormal=False, radius=6371)</code>","text":"<p>Parameters:     n_components:         Dimensionality of the target subspace.     manifold:         If callable, should return a (n x n) ideal distance matrix given y.</p> Source code in <code>smds/smds.py</code> <pre><code>def __init__(\n    self,\n    manifold: Callable[[np.ndarray], np.ndarray],\n    n_components: int = 2,\n    alpha: float = 0.1,\n    orthonormal: bool = False,\n    radius: float = 6371,\n):\n    \"\"\"\n    Parameters:\n        n_components:\n            Dimensionality of the target subspace.\n        manifold:\n            If callable, should return a (n x n) ideal distance matrix given y.\n    \"\"\"\n    self.n_components = n_components\n    self.manifold = manifold\n    self.W_ = None\n    self.alpha = alpha\n    self.orthonormal = orthonormal\n    self.radius = radius  # Only used for spherical manifolds\n    self._X_mean = None\n    self._Y_mean = None\n    if orthonormal and alpha != 0:\n        print(\"Warning: orthonormal=True and alpha!=0. alpha will be ignored.\")\n</code></pre>"},{"location":"#smds.SupervisedMDS.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the linear transformation W to match distances induced by labels y. Uses classical MDS + closed-form when all distances are defined, and switches to optimization if some distances are undefined (negative).</p> <p>Parameters:     X: array-like of shape (n_samples, n_features)         The input data to be transformed.     y: array-like of shape (n_samples,) or (n_samples, 2)         The labels or coordinates defining the ideal distances. Returns:     self: returns an instance of self.</p> Source code in <code>smds/smds.py</code> <pre><code>def fit(self, X: np.ndarray, y: np.ndarray) -&gt; \"SupervisedMDS\":\n    \"\"\"\n    Fit the linear transformation W to match distances induced by labels y.\n    Uses classical MDS + closed-form when all distances are defined,\n    and switches to optimization if some distances are undefined (negative).\n\n    Parameters:\n        X: array-like of shape (n_samples, n_features)\n            The input data to be transformed.\n        y: array-like of shape (n_samples,) or (n_samples, 2)\n            The labels or coordinates defining the ideal distances.\n    Returns:\n        self: returns an instance of self.\n    \"\"\"\n    X = np.asarray(X)\n    y = np.asarray(y).squeeze()  # Ensure y is 1D\n    D = self._compute_ideal_distances(y)\n\n    if np.any(D &lt; 0):\n        # Raise warning if any distances are negative\n        print(\"Warning: Distance matrix is incomplete. Using optimization to fit W.\")\n        mask = D &gt;= 0\n        rng = np.random.default_rng(42)\n        W0 = rng.normal(scale=0.01, size=(self.n_components, X.shape[1]))\n\n        result = minimize(self._masked_loss, W0.ravel(), args=(X, D, mask), method=\"L-BFGS-B\")\n        self.W_ = result.x.reshape((self.n_components, X.shape[1]))\n    else:\n        # Use classical MDS + closed-form least squares\n        Y = self._classical_mds(D)\n        self.Y_ = Y\n\n        self._X_mean = X.mean(axis=0)  # Centering\n        self._Y_mean = Y.mean(axis=0)  # Centering Y\n        X_centered = X - X.mean(axis=0)\n        Y_centered = Y - Y.mean(axis=0)\n        if self.orthonormal:\n            # Orthogonal Procrustes\n            M = Y_centered.T @ X_centered\n            U, _, Vt = np.linalg.svd(M)\n            self.W_ = U @ Vt\n        else:\n            if self.alpha == 0:\n                self.W_ = Y_centered.T @ np.linalg.pinv(X_centered.T)\n            else:\n                XtX = X_centered.T @ X_centered\n                XtX_reg = XtX + self.alpha * np.eye(XtX.shape[0])\n                XtX_inv = np.linalg.inv(XtX_reg)\n                self.W_ = Y_centered.T @ X_centered @ XtX_inv\n\n    return self\n</code></pre>"},{"location":"#smds.SupervisedMDS.fit_transform","title":"<code>fit_transform(X, y)</code>","text":"<p>Fit the model and transform X in one step. Parameters:     X: array-like of shape (n_samples, n_features)         The input data to be transformed.     y: array-like of shape (n_samples,) or (n_samples, 2) Returns:     X_proj: array of shape (n_samples, n_components)         The transformed data in the low-dimensional space.</p> Source code in <code>smds/smds.py</code> <pre><code>def fit_transform(self, X: np.ndarray, y: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Fit the model and transform X in one step.\n    Parameters:\n        X: array-like of shape (n_samples, n_features)\n            The input data to be transformed.\n        y: array-like of shape (n_samples,) or (n_samples, 2)\n    Returns:\n        X_proj: array of shape (n_samples, n_components)\n            The transformed data in the low-dimensional space.\n    \"\"\"\n    result: np.ndarray = self.fit(X, y).transform(X)\n    return result\n</code></pre>"},{"location":"#smds.SupervisedMDS.inverse_transform","title":"<code>inverse_transform(X_proj)</code>","text":"<p>Reconstruct the original input X from its low-dimensional projection.</p> <p>Parameters:     X_proj: array-like of shape (n_samples, n_components)         The low-dimensional representation of the input data.</p> <p>Returns:     X_reconstructed: array of shape (n_samples, original_n_features)         The reconstructed data in the original space.</p> Source code in <code>smds/smds.py</code> <pre><code>def inverse_transform(self, X_proj: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Reconstruct the original input X from its low-dimensional projection.\n\n    Parameters:\n        X_proj: array-like of shape (n_samples, n_components)\n            The low-dimensional representation of the input data.\n\n    Returns:\n        X_reconstructed: array of shape (n_samples, original_n_features)\n            The reconstructed data in the original space.\n    \"\"\"\n    if self.W_ is None:\n        raise RuntimeError(\"You must fit the model before calling inverse_transform.\")\n\n    X_proj = np.asarray(X_proj)\n\n    # Use pseudo-inverse in case W_ is not square or full-rank\n    # W_pinv = np.linalg.pinv(self.W_)\n    # Use regularized pseudo-inverse to avoid numerical issues\n    # W_pinv = self._regularized_pinv(self.W_)\n    W_pinv = self._truncated_pinv(self.W_)\n\n    X_centered: np.ndarray = (W_pinv @ X_proj.T).T\n\n    if hasattr(self, \"_X_mean\") and self._X_mean is not None:\n        result: np.ndarray = X_centered + self._X_mean\n        return result\n    else:\n        return X_centered\n</code></pre>"},{"location":"#smds.SupervisedMDS.load","title":"<code>load(filepath)</code>  <code>classmethod</code>","text":"<p>Load a model from disk. Returns:     An instance of SupervisedMDS.</p> Source code in <code>smds/smds.py</code> <pre><code>@classmethod\ndef load(cls, filepath: str) -&gt; \"SupervisedMDS\":\n    \"\"\"\n    Load a model from disk.\n    Returns:\n        An instance of SupervisedMDS.\n    \"\"\"\n    with open(filepath, \"rb\") as f:\n        obj = pickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not a {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"#smds.SupervisedMDS.save","title":"<code>save(filepath)</code>","text":"<p>Save the model to disk, including learned weights.</p> Source code in <code>smds/smds.py</code> <pre><code>def save(self, filepath: str) -&gt; None:\n    \"\"\"\n    Save the model to disk, including learned weights.\n    \"\"\"\n    if not os.path.exists(os.path.dirname(filepath)):\n        os.makedirs(os.path.dirname(filepath))\n    with open(filepath, \"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"#smds.SupervisedMDS.score","title":"<code>score(X, y, metric=StressMetrics.SCALE_NORMALIZED_STRESS)</code>","text":"<p>Evaluate embedding quality using SUPERVISED metric (uses y labels).</p> Source code in <code>smds/smds.py</code> <pre><code>def score(\n    self,\n    X: np.ndarray,\n    y: np.ndarray,\n    metric: StressMetrics = StressMetrics.SCALE_NORMALIZED_STRESS,\n) -&gt; float:\n    \"\"\"Evaluate embedding quality using SUPERVISED metric (uses y labels).\"\"\"\n    if self.W_ is None:\n        raise RuntimeError(\"Model must be fit before scoring.\")\n\n    D_ideal = self._compute_ideal_distances(y)\n\n    # Compute predicted pairwise distances\n    X_proj = self.transform(X)\n    n = X_proj.shape[0]\n    D_pred = np.linalg.norm(X_proj[:, np.newaxis, :] - X_proj[np.newaxis, :, :], axis=-1)\n\n    if metric == StressMetrics.NORMALIZED_KL_DIVERGENCE:\n        score_value = kl_divergence_stress(D_ideal, D_pred)\n        score_value = -score_value\n        return score_value\n\n    mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n    mask = mask &amp; (D_ideal &gt;= 0)\n    D_ideal_flat = D_ideal[mask]\n    D_pred_flat = D_pred[mask]\n\n    if metric == StressMetrics.SCALE_NORMALIZED_STRESS:\n        score_value = 1 - scale_normalized_stress(D_ideal_flat, D_pred_flat)\n    elif metric == StressMetrics.NON_METRIC_STRESS:\n        score_value = 1 - non_metric_stress(D_ideal_flat, D_pred_flat)\n    elif metric == StressMetrics.SHEPARD_GOODNESS_SCORE:\n        score_value = shepard_goodness_stress(D_ideal_flat, D_pred_flat)\n    elif metric == StressMetrics.NORMALIZED_STRESS:\n        score_value = 1 - normalized_stress(D_ideal_flat, D_pred_flat)\n    else:\n        raise ValueError(f\"Unknown metric: {metric}\")\n\n    return score_value\n</code></pre>"},{"location":"#smds.SupervisedMDS.transform","title":"<code>transform(X)</code>","text":"<p>Apply the learned transformation to X.</p> <p>Parameters:     X: array-like of shape (n_samples, n_features)         The input data to be transformed. Returns:     X_proj: array of shape (n_samples, n_components)         The transformed data in the low-dimensional space.</p> Source code in <code>smds/smds.py</code> <pre><code>def transform(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply the learned transformation to X.\n\n    Parameters:\n        X: array-like of shape (n_samples, n_features)\n            The input data to be transformed.\n    Returns:\n        X_proj: array of shape (n_samples, n_components)\n            The transformed data in the low-dimensional space.\n    \"\"\"\n    if self.W_ is None:\n        raise RuntimeError(\"You must fit the model before calling transform.\")\n    X = np.asarray(X)\n    if self._X_mean is not None:\n        # Center X using the same logic as during fit\n        X_centered = X - self._X_mean\n    else:\n        X_centered = X\n    X_proj: np.ndarray = (self.W_ @ X_centered.T).T\n    return X_proj\n</code></pre>"}]}