{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a39b307",
   "metadata": {},
   "source": [
    "# Family Tree Experiment\n",
    "\n",
    "## Experiment Overview\n",
    "\n",
    "The family tree experiment tests whether hierarchical concepts like family relationships intrinsically organize themselves into hierarchical structures in LLM latent spaces.\n",
    "\n",
    "SMDS allows studying embeddings with a hierarchical nature. Concepts such as family trees may intrinsically take such organization in the latent space. These are functional steps to validate this hypothesis:\n",
    "\n",
    "A dataset of paragraphs describing a family tree is prepared. Unique names are sampled from a known set (see emailed resources) and organized into a family tree. This family tree is then parsed into a text that describes it. E.g. \"Anna's parents are Sofia and Luke. Sofia's parents are Agnes and Robert. Luke's parents are George and Daniela.\" describes a family tree from a child to its grandparents;\n",
    "The paragraphs are fed to an LLM and activations in correspondance to the names tokens are recorded (see emailed resources);\n",
    "Manifold search is applied on these activations, using as features quantities like tree distance (1 for parent-child, 2 for grandparent-child, ...). Several hypothesis manifolds are compared and one is identified as the winner.\n",
    "\n",
    "### Hypothesis\n",
    "Concepts such as family trees may intrinsically take hierarchical organization in the latent space of LLMs.\n",
    "\n",
    "### Methodology\n",
    "1. **Data Generation**: Create paragraphs describing family relationships (parent-child: distance 1, grandparent-child: distance 2)\n",
    "2. **Activation Recording**: Feed paragraphs to LLMs and record activations at token positions corresponding to family member names\n",
    "3. **Manifold Search**: Apply SMDS (Supervised Multidimensional Scaling) on activations using tree distance as features\n",
    "4. **Analysis**: Compare hypothesis shapes (especially Hierarchical vs. Circular) to identify winning manifold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f1034",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_names():\n",
    "    path = \"smds/demos/resources/names.csv\"\n",
    "    if not os.path.exists(path):\n",
    "        path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../resources/names.csv\"))\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    return df[\"name\"].tolist()\n",
    "\n",
    "\n",
    "def generate_family_tree_data(names, n_samples=50):\n",
    "    data = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        if len(names) < 7:\n",
    "            raise ValueError(\"Not enough names in the dataset to generate a depth-2 tree (needs 7 unique names).\")\n",
    "\n",
    "        family_names = random.sample(names, 7)\n",
    "\n",
    "        child = family_names[0]\n",
    "        p1, p2 = family_names[1], family_names[2]\n",
    "        gp1, gp2 = family_names[3], family_names[4]\n",
    "        gp3, gp4 = family_names[5], family_names[6]\n",
    "\n",
    "        base_text = (\n",
    "            f\"{child}'s parents are {p1} and {p2}. \"\n",
    "            f\"{p1}'s parents are {gp1} and {gp2}. \"\n",
    "            f\"{p2}'s parents are {gp3} and {gp4}. \"\n",
    "            f\"Therefore, the family's youngest member is {child}.\"\n",
    "        )\n",
    "\n",
    "        for i in range(7):\n",
    "            target_name = family_names[i]\n",
    "\n",
    "            text = base_text + f\" The family member is {target_name}.\"\n",
    "\n",
    "            if i == 0:\n",
    "                dist = 0\n",
    "            elif 1 <= i <= 2:\n",
    "                dist = 1\n",
    "            elif 3 <= i <= 6:\n",
    "                dist = 2\n",
    "\n",
    "            entry = {\"text\": text, \"names\": family_names, \"target_map\": {target_name: dist}}\n",
    "            data.append(entry)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90ed5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from smds.demos.family_tree.data_generation import generate_family_tree_data, load_names\n",
    "from smds.shapes.discrete_shapes.hierarchical import HierarchicalShape\n",
    "from smds.pipeline.discovery_pipeline import discover_manifolds, DEFAULT_SHAPES\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def find_last_token_idx(tokenizer, text, target):\n",
    "    encoding = tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "    offset_mapping = encoding[\"offset_mapping\"]\n",
    "\n",
    "    target_start = text.rfind(target)\n",
    "    if target_start == -1:\n",
    "        return -1\n",
    "    target_end = target_start + len(target)\n",
    "\n",
    "    matched_idx = -1\n",
    "    for idx, (tok_start, tok_end) in enumerate(offset_mapping):\n",
    "        if tok_start == tok_end == 0:\n",
    "            continue\n",
    "\n",
    "        if not (tok_end <= target_start or tok_start >= target_end):\n",
    "            matched_idx = idx\n",
    "            pass\n",
    "\n",
    "    return matched_idx\n",
    "\n",
    "\n",
    "def get_activations_all_layers(df, model, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    layer_data = {}\n",
    "\n",
    "    print(\"Recording activations for all layers...\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        target_map = row[\"target_map\"]\n",
    "\n",
    "        input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "        for layer_idx, hidden_state_tensor in enumerate(outputs.hidden_states):\n",
    "            if layer_idx not in layer_data:\n",
    "                layer_data[layer_idx] = {\"activations\": [], \"distances\": []}\n",
    "\n",
    "            hidden_state = hidden_state_tensor.squeeze(0).cpu().numpy()\n",
    "\n",
    "            for name, dist in target_map.items():\n",
    "                idx = find_last_token_idx(tokenizer, text, name)\n",
    "                if idx != -1 and idx < len(hidden_state):\n",
    "                    vect = hidden_state[idx]\n",
    "                    layer_data[layer_idx][\"activations\"].append(vect)\n",
    "                    layer_data[layer_idx][\"distances\"].append(dist)\n",
    "\n",
    "    final_data = {}\n",
    "    for layer_idx, data in layer_data.items():\n",
    "        if len(data[\"activations\"]) > 0:\n",
    "            final_data[layer_idx] = (\n",
    "                np.array(data[\"activations\"]),\n",
    "                np.array(data[\"distances\"])\n",
    "            )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "    all_names = load_names()\n",
    "    df = generate_family_tree_data(all_names, n_samples=50)\n",
    "\n",
    "    all_layers_data = get_activations_all_layers(df, model, tokenizer)\n",
    "\n",
    "    hierarchical_shape = HierarchicalShape(level_distances=[5.0, 1.0])\n",
    "\n",
    "    summary_results = []\n",
    "\n",
    "    for layer_idx in sorted(all_layers_data.keys()):\n",
    "        print(f\"Analyzing Layer {layer_idx}\")\n",
    "        X, y = all_layers_data[layer_idx]\n",
    "        y = y.astype(np.float64)\n",
    "\n",
    "        y_hier = np.zeros((len(y), 2), dtype=np.float64)\n",
    "        y_hier[:, 1] = y\n",
    "\n",
    "        res_hier, _ = discover_manifolds(\n",
    "            X,\n",
    "            y_hier,\n",
    "            shapes=[hierarchical_shape],\n",
    "            experiment_name=f\"family_tree_layer_{layer_idx}_hier\",\n",
    "            model_name=\"gpt2\",\n",
    "            n_folds=5,\n",
    "            n_jobs=-1,\n",
    "            save_results=False,\n",
    "            create_visualization=False,\n",
    "        )\n",
    "\n",
    "        if not res_hier.empty:\n",
    "            row = res_hier.iloc[0]\n",
    "            summary_results.append({\n",
    "                \"layer\": layer_idx,\n",
    "                \"shape\": \"HierarchicalShape\",\n",
    "                \"stress\": row[\"mean_scale_normalized_stress\"]\n",
    "            })\n",
    "\n",
    "        res_shapes, _ = discover_manifolds(\n",
    "            X,\n",
    "            y,\n",
    "            shapes=DEFAULT_SHAPES,\n",
    "            experiment_name=f\"family_tree_layer_{layer_idx}_shapes\",\n",
    "            model_name=\"gpt2\",\n",
    "            n_folds=5,\n",
    "            n_jobs=-1,\n",
    "            save_results=False,\n",
    "            create_visualization=False,\n",
    "        )\n",
    "\n",
    "        if not res_shapes.empty:\n",
    "            for _, row in res_shapes.iterrows():\n",
    "                summary_results.append({\n",
    "                    \"layer\": layer_idx,\n",
    "                    \"shape\": row[\"shape\"],\n",
    "                    \"stress\": row[\"mean_scale_normalized_stress\"]\n",
    "                })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_results)\n",
    "    print(summary_df)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for shape_name in summary_df[\"shape\"].unique():\n",
    "        subset = summary_df[summary_df[\"shape\"] == shape_name]\n",
    "        subset = subset.sort_values(\"layer\")\n",
    "        plt.plot(subset[\"layer\"], subset[\"stress\"], marker='o', label=shape_name)\n",
    "\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Stress\")\n",
    "    plt.title(\"Stress vs Layer by Shape\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"stress_vs_layer.png\")\n",
    "    print(\"Plot saved to stress_vs_layer.png\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from smds.demos.family_tree.data_generation import generate_family_tree_data, load_names\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def find_last_token_idx(tokenizer, text, target):\n",
    "    encoding = tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "    offset_mapping = encoding[\"offset_mapping\"]\n",
    "\n",
    "    target_start = text.rfind(target)\n",
    "    if target_start == -1:\n",
    "        return -1\n",
    "    target_end = target_start + len(target)\n",
    "\n",
    "    matched_idx = -1\n",
    "    for idx, (tok_start, tok_end) in enumerate(offset_mapping):\n",
    "        if tok_start == tok_end == 0:\n",
    "            continue\n",
    "\n",
    "        if not (tok_end <= target_start or tok_start >= target_end):\n",
    "            matched_idx = idx\n",
    "            pass\n",
    "\n",
    "    return matched_idx\n",
    "\n",
    "\n",
    "def get_activations(df, model, tokenizer, layer=-1):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    distances = []\n",
    "\n",
    "    print(\"Recording activations...\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        target_map = row[\"target_map\"]\n",
    "\n",
    "        input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "        hidden_state = outputs.hidden_states[layer].squeeze(0).cpu().numpy()\n",
    "\n",
    "        for name, dist in target_map.items():\n",
    "            idx = find_last_token_idx(tokenizer, text, name)\n",
    "            if idx != -1 and idx < len(hidden_state):\n",
    "                vect = hidden_state[idx]\n",
    "                activations.append(vect)\n",
    "                distances.append(dist)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return np.array(activations), np.array(distances)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Setting up experiment...\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "    model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")\n",
    "        raise e\n",
    "\n",
    "    print(\"Generating data...\")\n",
    "    all_names = load_names()\n",
    "    df = generate_family_tree_data(all_names, n_samples=50)\n",
    "    print(f\"Generated {len(df)} family trees.\")\n",
    "    print(f\"Sample text: {df.iloc[0]['text']}\")\n",
    "\n",
    "    X, y = get_activations(df, model, tokenizer, layer=-1)\n",
    "\n",
    "    print(f\"Collected data shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "    print(\"\\nRunning Manifold Discovery Pipeline...\")\n",
    "\n",
    "    from smds.pipeline.discovery_pipeline import discover_manifolds\n",
    "\n",
    "    y = y.astype(np.float64)\n",
    "    X = X.astype(np.float64)\n",
    "\n",
    "    results_df, save_path = discover_manifolds(\n",
    "        X,\n",
    "        y,\n",
    "        experiment_name=\"family_tree_experiment\",\n",
    "        model_name=\"llama\",\n",
    "        n_folds=5,\n",
    "        n_jobs=-1,\n",
    "        save_results=True,\n",
    "        create_visualization=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nPipeline Results:\")\n",
    "    print(results_df[[\"shape\", \"mean_scale_normalized_stress\", \"std_scale_normalized_stress\", \"error\"]])\n",
    "\n",
    "    if not results_df.empty:\n",
    "        winner = results_df.iloc[0]\n",
    "        print(f\"\\nWinner: {winner['shape']} (Mean Score: {winner['mean_scale_normalized_stress']:.4f})\")\n",
    "\n",
    "    print(\"\\nRunning Hierarchical Analysis...\")\n",
    "    from smds.shapes.discrete_shapes.hierarchical import HierarchicalShape\n",
    "\n",
    "    y_hier = np.zeros((len(y), 2), dtype=np.float64)\n",
    "    y_hier[:, 1] = y\n",
    "\n",
    "    hierarchical_shape = HierarchicalShape(level_distances=[5.0, 1.0])\n",
    "\n",
    "    results_hier, _ = discover_manifolds(\n",
    "        X,\n",
    "        y_hier,\n",
    "        shapes=[hierarchical_shape],\n",
    "        save_path=save_path,  # Append to existing results\n",
    "        n_folds=5,\n",
    "        n_jobs=-1,\n",
    "        save_results=True,\n",
    "        create_visualization=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nHierarchical Results:\")\n",
    "    print(results_hier[[\"shape\", \"mean_scale_normalized_stress\", \"std_scale_normalized_stress\", \"error\"]])\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb247937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from smds.demos.family_tree.data_generation import generate_family_tree_data, load_names\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def find_last_token_idx(tokenizer, text, target):\n",
    "    encoding = tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "    offset_mapping = encoding[\"offset_mapping\"]\n",
    "\n",
    "    target_start = text.rfind(target)\n",
    "    if target_start == -1:\n",
    "        return -1\n",
    "    target_end = target_start + len(target)\n",
    "\n",
    "    matched_idx = -1\n",
    "    for idx, (tok_start, tok_end) in enumerate(offset_mapping):\n",
    "        if tok_start == tok_end == 0:\n",
    "            continue\n",
    "\n",
    "        if not (tok_end <= target_start or tok_start >= target_end):\n",
    "            matched_idx = idx\n",
    "            pass\n",
    "\n",
    "    return matched_idx\n",
    "\n",
    "\n",
    "def get_activations(df, model, tokenizer, layer=-1):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    distances = []\n",
    "\n",
    "    print(\"Recording activations...\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        target_map = row[\"target_map\"]\n",
    "\n",
    "        input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "        hidden_state = outputs.hidden_states[layer].squeeze(0).cpu().numpy()\n",
    "\n",
    "        for name, dist in target_map.items():\n",
    "            idx = find_last_token_idx(tokenizer, text, name)\n",
    "            if idx != -1 and idx < len(hidden_state):\n",
    "                vect = hidden_state[idx]\n",
    "                activations.append(vect)\n",
    "                distances.append(dist)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return np.array(activations), np.array(distances)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Setting up experiment...\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "    model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "    print(\"Generating data...\")\n",
    "    all_names = load_names()\n",
    "    df = generate_family_tree_data(all_names, n_samples=50)\n",
    "    print(f\"Generated {len(df)} family trees.\")\n",
    "    print(f\"Sample text: {df.iloc[0]['text']}\")\n",
    "\n",
    "    X, y = get_activations(df, model, tokenizer, layer=-1)\n",
    "\n",
    "    print(f\"Collected data shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "    print(\"\\nRunning Manifold Discovery Pipeline...\")\n",
    "\n",
    "    from smds.pipeline.discovery_pipeline import discover_manifolds\n",
    "\n",
    "    y = y.astype(np.float64)\n",
    "    X = X.astype(np.float64)\n",
    "\n",
    "    results_df, save_path = discover_manifolds(\n",
    "        X,\n",
    "        y,\n",
    "        experiment_name=\"family_tree_experiment\",\n",
    "        model_name=\"qwen\",\n",
    "        n_folds=5,\n",
    "        n_jobs=-1,\n",
    "        save_results=True,\n",
    "        create_visualization=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nPipeline Results:\")\n",
    "    print(results_df[[\"shape\", \"mean_scale_normalized_stress\", \"std_scale_normalized_stress\", \"error\"]])\n",
    "\n",
    "    if not results_df.empty:\n",
    "        winner = results_df.iloc[0]\n",
    "        print(f\"\\nWinner: {winner['shape']} (Mean Score: {winner['mean_scale_normalized_stress']:.4f})\")\n",
    "\n",
    "    print(\"\\nRunning Hierarchical Analysis...\")\n",
    "    from smds.shapes.discrete_shapes.hierarchical import HierarchicalShape\n",
    "\n",
    "    y_hier = np.zeros((len(y), 2), dtype=np.float64)\n",
    "    y_hier[:, 1] = y\n",
    "\n",
    "    hierarchical_shape = HierarchicalShape(level_distances=[5.0, 1.0])\n",
    "\n",
    "    results_hier, _ = discover_manifolds(\n",
    "        X,\n",
    "        y_hier,\n",
    "        shapes=[hierarchical_shape],\n",
    "        save_path=save_path,  # Append to existing results\n",
    "        n_folds=5,\n",
    "        n_jobs=-1,\n",
    "        save_results=True,\n",
    "        create_visualization=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nHierarchical Results:\")\n",
    "    print(results_hier[[\"shape\", \"mean_scale_normalized_stress\", \"std_scale_normalized_stress\", \"error\"]])\n",
    "\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175186d3",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- **GPT-2:** 0.694 (Circular) vs. 0.749 (Hierarchical)\n",
    "- **Llama:** 0.841 (Circular) vs. 0.878 (Hierarchical)\n",
    "- **Qwen:** 0.787 (Circular) vs. 0.834 (Hierarchical)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervised-multidimensional-scaling (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
